
To support a multi-node Hurd cluster, the libpager used by filesystem
translators needs to support multiple clients (i.e, multiple kernels
mmap'ing files).

GENERAL NOTES

pager_read_page() is expected to allocate memory (unless it returns an
error) and pass it to libpager, which is responsible for deallocating
it (actually by passing it to the kernel).

pager_write_page() does no memory allocation or deallocation.  It
receives allocated memory and leaves it allocated, with libpager
responsible for dellocation (or passing it to the kernel).

If we're servicing a page read-only to multiple clients, where do we
get the data from?  If our local kernel has a copy, we almost
certainly want to get it there, since it's just a manner of flipping
bits in a hardware page table to obtain a new "copy" of the data.
Otherwise, we probably want to get the data from the local disk, but
if the disk is very busy and we've got fast network connections, we
might want to get that data from another node in the cluster.

How do we figure out which client is the local kernel?

DISTRIBUTED LIBPAGER.  We could use a shim process on remote nodes, to
allow requests for an existing page go to a node that holds a copy of
that page, instead of to the node with the disk.  Two ways I can
imagine this.  Either ext2fs forks off multiple processes on different
nodes, or a mechanism is developed to detect when a port is remote,
figure out which node it (currently) resides on, and then libpager can
fork a process and push it to the other node, invisible to ext2fs
proper.


ON REMOVING pager_offer_page()

Brent Baccala wrote:

> I've reviewed the existing code, and I have a problem with the
> function pager_offer_page().

> First, the API is problematic, since pager_offer_page() is a call from
> the memory server (i.e, ext2fs) into the libpager library, instructing
> the library to offer a page to the client (i.e, the kernel) that
> hasn't been solicited by the client.  The problem is that the function
> parameters don't indicate which client to offer the page to.

> Second, I can't find anywhere in the hurd source tree where this
> function is actually used.

> Third, why would we want this feature?  Why would a memory server ever
> want to send an unsolicited page to a client?

> So, I propose deprecating pager_offer_pager() by simply removing it
> from the library.

> Any objections?

Kalle Olavi Niemitalo <kon@iki.fi> wrote:

> Commit 84cf9c0f312637b670cc87224ff7e7c4da659e36 on 2013-09-17
> removed the ufs directory, in which the offer_data function used
> to call pager_offer_page.  The last argument of pager_offer_page
> always pointed to a page that was part of the global zeroblock,
> which was the size of a filesystem block and filled with zeroes.

> One of the offer_data calls was preceded by a comment:

>   /* Make sure that any pages of this block which just became allocated
>      don't get paged in from disk. */

> I don't know how ext2fs makes sure of that, or whether
> pager_offer_page might again be needed for the same purpose in
> the future.



THE PAGEMAP

struct pagemap_entry {
   port_t client_with_write_access;
   port_t clients_with_read_access[];

   /* A list of the clients waiting for access, and what kind of access they are waiting for */
   port_t clients_waiting[];
   boolean clients_waiting_for_write[];
}

How to maintain the pagemap for a large number of clients?  More than
32 clients, actually, so that a pointer becomes more efficient than a
bitmap.  So, each page has a pointer to a structure indicating which
clients currently hold copies of the page.  We anticipate that many
pages (say, all the pages in a single shared library) will have the
same set of clients, so there's one structure for each combination of
clients, with multiple pages pointing to it.

Each file corresponds to a separate memory object, and separate memory
objects get separate control ports in the kernel.  A future
enhancement could be for the kernel to use a single control port for
all of its memory objects, allowing libpager to reduce the number of
these combination structures, if different files have the same usage
pattern (a program and some of its shared libraries, for example).

What happens when a page gets a new client (or loses one)?  We have to
search in the structures for the new combination, and create a new
structure if the desired combination doesn't exist yet.

[[ To speed this process, each structure can maintain pointers to
accelerate this mapping.  Each structure would have an "add table"
would maintain mappings like "add client 123 -> structure 0x80fadde0".
If the "add table" doesn't have an entry, then we need to search all
the structures to find one.  The problem with this is the need to
invalidate those pointers when a structure is deallocated.  Keep this
idea for a future enhancement. ]]

How can we organize the structures?  First, by the number of clients.
We'll always know how many clients are in the structure we're
searching for, so if we've got six clients and are adding one, we'll
search in the seven-client tables.  We can use a hash table or a tree.

The pagemap structures should contain a count of the number of pages
pointing to them, to facilitate deallocation when the count drops to
zero.  That interferes with the "add table" mapping described above.

The current kernel implementation seems to be to request pages one at
a time, as the process attempts to access them.

For writable pages, there can be a queue of clients waiting for a
page.  A client can be waiting for multiple pages, if separate threads
(or processes) on a single node are accessing different parts of the
same file.

Pagemaps can be potentially large, so a pagemap entry should be a
single pointer.

Putting a client on an empty queue triggers lock requests to all
clients in the working set, with the exception of the requesting
client itself, if it's already got read access and is requesting write
access.  Once the working set size drops to zero (or one), then the
original request can be satisfied.

In the meantime, additional clients can be added to the queue.  Each
client should be allowed access to a page for a period of time before
a lock request is sent.  Is the easiest way to do this to use the
timeout parameter on mach_msg?

Current implementation waits until the kernel returns a page, then
writes it to disk.  If a request for the page comes in before the
write completes, we wait for the write to finish, then send it right
back out without needing a read.

The new implementation will be handling pages as they're passed from
one client to another.  Should they be written out each time they are
handled?  Not write them at all until they're finally released?  Have
some kind of timer or counter to write them at a controlled pace?
Initially, we'll not write them at all until they're finally released,
which mimics the current behavior.

So when the last client returns a page, we look to see if anything is
in the wait queue.  If so, the first client(s) in the queue get the
pages.  If not, we flag that a write is in progress and start it.
When it completes, we check the queue again to see if anything is now
waiting.  If so, we service it.  If not, we discard the data and
notify the user that the page has been evicted.



C++ PAGEMAP (probably not)

What's not so clear is how to code the pagemap itself.  A straight-up
array of pointers?  Easy enough to understand, but then we have to
code reference counting to know when those dynamic structures can be
deallocated.  An array of shared_ptr's?  Simplifies the code, because
it does all the reference counting for us, but at the cost of making
the array four times bigger than it needs to be.  A custom class with
a clever copy constructor?  Then we just assign into the array and the
copy constructor takes care of either finding an existing pagemap
structure or creating a new one, at the cost of obscuring the fact
that "pagemap[i] = new_client_list;" is far more complex than a simple
assignment.

Right now, I'm thinking to go with the clever copy constructor with a
(mandatory, really) paragraph-long comment explaining its function.
Use shared_ptr's for now, maybe re-coding them later if we decide that
the library's memory footprint is out of hand.

What I want to avoid is to start looking at that code, saying "coping
all these queues and lists is inefficient" (it is), and start adding
all kinds of C++ tricks to speed it up.  Just write it so that it's
simple and clear, and if performance becomes an issue, revisit it
later.  Or make all those queues and lists private, and add all kinds
of member functions to abstract access to them.  Just leave them
public and access them directly; we're not hiding anything from anyone
but ourselves.


Richard Braun <rbraun@sceen.net>:

> From my fifteen years or so experience working in various projects with
> C++ and other languages, my opinion is that C++ is never the best
> choice. It makes you trade lines of code for increased complexity in
> understanding and following the code. You should either go with C for
> excellent control, or another higher level langguage for e.g. user
> interfaces and tasks that don't require the highest performance.

> I really don't think the problem you describe would be so hard to solve
> in C.


OLD PAGETABLE

PAGINGOUT - set this flag when we get a data return, clear it after the write is finished
PAGEINWAIT - if we get a data request on a page whose's PAGINGOUT, flag it PAGEINWAIT
   kernel has requested them, but the flag doesn't indiciate _which_ kernel requested them
WRITEWAIT - if we get a data return on a page whose's PAGINGOUT, flag it WRITEWAIT
INVALID - set if we got an error writing the page back to the filesystem (actual error code is discarded)
   Future requests for this page will get an m_o_data_error (EIO)
TWO 2 BIT ERROR CODES - ERROR and NEXTERROR
   NEXTERROR - only set if m_o_data_unlock gets an error from pager_unlock_page(), in which
      case libpager answers the unlock with a m_o_lock_request (the flush varient) and expects
      an upcoming m_o_data_request (for write access) to be answered with m_o_data_error
   ERROR - set to EIO as a result of a read error (actual error code is discarded)
      an unlock error will get propagated from NEXTERROR to ERROR
      pager_get_error() will report error back to filesystem

ERRORS

read error on m_o_data_request - reply with m_o_data_error (EIO) and mark
write error on m_o_data_return - flag page INVALID unless we can page it right back out again (error code dropped)
unlock error on m_o_data_unlock - evict the page and report error back on next m_o_data_request

misaligned requests / bad length - request is dropped and error logged
pagemap resize error - data request is ignored

THE PSEUDOCODE

if filesystem creates libpager with notify_on_evict TRUE, then all the pages supplied to
the kernel are flagged "precious" and are returned to libpager on eviction.  The data itself
is discarded.  ext2fs uses this feature.

m_o_data_request: (kernel requesting a single page)
  REQUESTED access IS LARGELY IGNORED; FILESYSTEM GRANTS WRITE ACCESS EVEN IF READ WAS REQUESTED
     FILESYSTEM GRANTS READ ACCESS EVEN IF WRITE WAS REQUESTED (unless a NEXTERROR is pending)

  if the page is PAGINGOUT, flag it PAGEINWAIT and do nothing except NEXTERROR handling
  if the page is flagged with a NEXTERROR and WRITE ACCESS WAS REQUESTED, send a m_o_data_error message,
        move NEXTERROR to ERROR, and clear NEXTERROR
     if write access was not requested, ignore NEXTERROR
  unlock pager
  read the page (unless PAGINGOUT or an error) with pager_read_page()
  if pager_read_page() returned an error, mark page with ERROR=EIO and return m_o_data_error
  if no error, send it to kernel with m_o_data_supply and read/write status supplied by filesystem and clear ERROR

m_o_data_return: (kernel returning pages)
  npages = length / __vm_page_size;
  pm_entries points to 'npages' entries in pagemap
  if any of the pages are flagged PAGINGOUT, flag them WRITEWAIT and wait to be signaled that they're paged out
  flag all these pages PAGINGOUT
  if any locks are pending on these pages, increment pending_writes in the lock request
  unlock the pager
  call pager_write_page() on all the pages
  reaquire the pager lock
  if any of the pages are now flagged WRITEWAIT, signal the condition variable
  if any of the pager_write_page() calls returned error and are not flagged PAGEINWAIT, mark those pages INVALID
  if any of the pages are flagged PAGEINWAIT, transmit them in a m_o_data_supply message
  for the lock requests we incremented pending_writes on, decrement pending_writes, and signal wakeup
    if there's no more pending_writes or locks_pending
  if client requested notify_on_evict, call pager_notify_evict() for any pages that were evicted and
    didn't get shipped back out in an m_o_data_supply message, and clear their ERRORs and NEXTERRORs

m_o_data_unlock: (kernel requesting write access)
  routine itself never locks pager (but lock_object does)
  call pager_unlock_page()
  no error -> answer with m_o_data_lock (lock_object; not synchronous)
  error -> answer with m_o_data_lock (lock_object; flush variant; not synchronous)

lock_object: (several types: flush, sync, return, response to an unlock request)
  wrapper around m_o_data_lock message
  if sync requested, add to lock_requests list with locks_pending++ and threads_waiting++
     after m_o_lock_request message sent, wait for locks_pending and pending_writes to drop to zero,
     then decrement threads_waiting and remove lock_requests if zero
     if should_flush, clear PM_INCORE flag in pagemap
  PM_INCORE flags don't get cleared if sync wasn't requested

  lock_object() called by pager_ calls to flush, sync, and return data from kernel,
    as well as m_o_data_unlock

  if a m_o_data_return comes in while waiting for a synchronous lock to complete,
    we wait for the write to finish before returning from the lock
    the data return could be triggered by the lock request (i.e, a sync or a return)
  if a lock request comes in while a write is happening, we don't do anything to synchronize them

m_o_lock_completed:
  find lock in list of lock requests, decrement locks_pending, wake up waiter if no more locks_pending or pending_writes


NEW PAGETABLE

struct pagemap_entry {
   /* ACCESSLIST */
   port_t client_with_write_access;
   port_t clients_with_read_access[];

   /* WAITLIST */
   /* A list of the clients waiting for access, in order of arrival, and what kind of access they are waiting for */
   port_t clients_waiting[];
   boolean clients_waiting_for_write[];

   /* Flags */
   PAGINGOUT - set this flag when we get a data return, clear it after the write is finished
   PAGEINWAIT - if we get a data request on a page whose's PAGINGOUT, flag it PAGEINWAIT
      kernel has requested them, but the flag doesn't indiciate _which_ kernel requested them
   WRITEWAIT - if we get a data return on a page whose's PAGINGOUT, flag it WRITEWAIT
   INVALID - set if we got an error writing the page back to the filesystem (actual error code is discarded)
      Future requests for this page will get an m_o_data_error (EIO)
   TWO 2 BIT ERROR CODES - ERROR and NEXTERROR
      NEXTERROR - only set if m_o_data_unlock gets an error from pager_unlock_page(), in which
         case libpager answers the unlock with a m_o_lock_request (the flush varient) and expects
         an upcoming m_o_data_request (for write access) to be answered with m_o_data_error
      ERROR - set to EIO as a result of a read error (actual error code is discarded)
         an unlock error will get propagated from NEXTERROR to ERROR
         pager_get_error() will report error back to filesystem
}

NEW PSEUDOCODE

m_o_data_request: (kernel requesting a single page)

  if the page is PAGINGOUT, add requesting client to WAITLIST and do nothing except NEXTERROR handling
  if WAITLIST is not empty, add requesting client to WAITLIST and do nothing except NEXTERROR handling
  if the page is flagged with a NEXTERROR and WRITE ACCESS WAS REQUESTED, send a m_o_data_error message,
        move NEXTERROR to ERROR, and clear NEXTERROR
     NEXTERROR needs be a list of errors and clients to send them to (or does it?)
     if write access was not requested, ignore NEXTERROR
  if this client is already on ACCESSLIST, print error message and do nothing
  if another client has WRITE access (WAITLIST is empty), add requesting client to WAITLIST,
     and send lock request (return data; no reply)
     if we want read access, this is a lock to remove WRITE permission
     if we want write access, the lock has to be a flush
  if WRITE access is requested and other clients have any access, add requesting client to WAITLIST,
     and send lock requests (asynchronous; reply requested)
  if ACCESSLIST is empty or READ access is requested and only READ clients are on ACCESSLIST,
     add this client to ACCESSLIST
  unlock pager
  read the page (if we just put this client on ACCESSLIST) with pager_read_page()
  if pager_read_page() returned an error, mark page with ERROR=EIO and return m_o_data_error
  if no error, send it to kernel with m_o_data_supply and read/write status requested and supplied by filesystem,
     and clear ERROR

ISSUE:
  this logic could cause multiple overlapping calls to pager_read_page() if a bunch of clients
    request READ access near simultaneously

RACE CONDITION:
  client requests access
  client is put on WAITLIST and pager_read_page() begins
  another client requests contradictory access via m_o_data_request
  NOT [ we send a lock request to original client, even though it hasn't gotten the data yet! ]
  NOT [ then pager_read_page() completes, and we send the data to the original client! ]
  YES [ no messages are sent since WAITLIST is not empty ]
  YES [ new client is put on the end of WAITLIST ]

RACE CONDITION:
  client B has READ access
  client A requests WRITE access (m_o_data_request)
  lock (flush) request is sent to client B and client A is added to WAITLIST
  nearly simultaneously, client B requests WRITE access (unlock)
  do nothing, since client B wouldn't have sent unlock request if it had already received lock request,
    so it will interpret the lock request as an answer to the unlock request

m_o_lock_completed:
  find lock in list of lock requests, decrement locks_pending, wake up waiter if no more locks_pending or pending_writes
  if lock corresponds to a single page, find it in the pagetable
    m_o_lock_completed could have been sent in response to a LOCKWAIT, or a fs flush, sync, return (can't tell which)
    if this client had WRITE access, print error (should have used m_o_data_return instead of m_o_lock_completed)
    otherwise, remove client from ACCESSLIST
      if ACCESSLIST is empty, use m_o_data_supply to supply first set of WAITLIST clients
        and move those clients to ACCESSLIST
        (a client with no access requested WRITE access and had to wait for other clients to flush)
      if ACCESSLIST has a single client with READ access and it's also the first client on WAITLIST requesting WRITE access,
        call pager_unlock_page()
        no error -> send m_o_lock_object (no reply), remove it from WAITLIST,
           and upgrade its ACCESSLIST entry to reflect WRITE access
        error -> send m_o_data_lock (flush variant, no reply)
        (a client with READ access requested WRITE access and had to wait for other clients with READ access to flush)
      otherwise, if ACCESSLIST has multiple clients, or a single client that's not first on WAITLIST,
        then we're still waiting for them to answer their locks, so do nothing
      what if WAITLIST still has clients on it after sending messages?
         [ ] use a timeout before sending more lock requests?
         [X] send them right away to let the kernel know we want these pages right back?


m_o_data_unlock: (kernel requesting write access when it's already got read access)
  ASSERT: this client already on ACCESSLIST with read access
  routine itself never locks pager (but lock_object does)
  if WAITLIST is not empty, do nothing (we're already trying to flush everything on ACCESSLIST)
  if there's other clients on ACCESSLIST, send lock requests to other clients (flush; async; reply requested)
  otherwise, call pager_unlock_page()
    no error -> answer with m_o_data_lock (lock_object; not synchronous)
    error -> answer with m_o_data_lock (lock_object; flush variant; not synchronous)

ISSUE: if multiple clients with READ access attempt to unlock near simultaneously, this
  logic will trigger multiple lock requests (a set for each client attempting to unlock)

lock_object: (several types: flush, sync, return, response to an unlock request)
  NEW MODE NEEDED: asynchronous, but reply requested
  wrapper around m_o_data_lock message
  if sync requested, add to lock_requests list with locks_pending++ and threads_waiting++
     after m_o_lock_request message sent, wait for locks_pending and pending_writes to drop to zero,
     then decrement threads_waiting and remove lock_requests if zero

  lock_object() called by pager_ calls to flush, sync, and return data from kernel,
    as well as m_o_data_unlock

  if a m_o_data_return comes in while waiting for a synchronous lock to complete,
    we wait for the write to finish before returning from the lock
    the data return could be triggered by the lock request (i.e, a sync or a return)
  if a lock request comes in while a write is happening, we don't do anything to synchronize them

m_o_data_return: (kernel returning pages)
  (this can not be used in liu of a lock completed message for a WRITE,
     because it doesn't indicate if the kernel still maintains WRITE access)
  npages = length / __vm_page_size;
  pm_entries points to 'npages' entries in pagemap
  if any of the pages are flagged PAGINGOUT, flag them WRITEWAIT and wait to be signaled that they're paged out
     (kernel can sync pages at will; multiple syncs could be concurrent)
  flag all these pages PAGINGOUT
  if any locks are pending on these pages, increment pending_writes in the lock request
  unlock the pager
  call pager_write_page() on all the pages
  reacquire the pager lock
  if any of the pages are now flagged WRITEWAIT, signal the condition variable
  if any of the pager_write_page() calls returned error and are not flagged PAGEINWAIT, mark those pages INVALID
  if any of the pages are flagged PAGEINWAIT, transmit them in a m_o_data_supply message
  for the lock requests we incremented pending_writes on, decrement pending_writes, and signal wakeup
    if there's no more pending_writes or locks_pending
  if client requested notify_on_evict, call pager_notify_evict() for any pages that were evicted and
    didn't get shipped back out in an m_o_data_supply message, and clear their ERRORs and NEXTERRORs


  if the first client on WAITLIST is requesting READ access,
    then the lock request was only to revoke WRITE access
    re-flag this client on ACCESSLIST with READ access
    use m_o_data_supply to supply first set of WAITLIST clients (all requesting READ access)
    remove those clients from WAITLIST and move them to ACCESSLIST
  otherwise, the first client on WAITLIST is requesting WRITE access
    ASSERT: kernel_copy is false
    remove this client from ACCESSLIST (ASSERT: ACCESSLIST should now be empty)
    use m_o_data_supply to supply first WAITLIST client (requesting WRITE access)
    move that client from WAITLIST to ACCESSLIST
  if WAITLIST still has clients on it, send lock requests out to everyone on ACCESSLIST


ISSUES:
  before pager_write_page() returns, we can't call pager_read_page() or pager_write_page()
  after pager_write_page() returns, we might have added additional clients to WAITLIST,
    but did we add them while waiting for pager_write_page() or were they there before?
    if ACCESSLIST clients have READ access, and first WAITLIST clients are requested READ access, they are new
    if ACCESSLIST clients have READ access, and first WAITLIST client is requesting WRITE access,
      they may or may not be new
    if ACCESSLIST client has WRITE access, and WAITLIST isn't empty,
      they may or may not be new
    if we wait until pager_write_page() returns to send lock requests, we avoid having to figure out
      if we've already sent lock requests, and introduce some delay to let clients use the data

HOW ABOUT:
  before calling pager_write_page(), service the first batch of clients on WAITLIST
     and move them to ACCESSLIST, but send no lock requests
  after pager_write_page(), service any compatible WAITLIST clients and move them to ACCESSLIST
  if there are still outstanding WAITLIST clients, send lock requests to everyone on ACCESSLIST

RACE CONDITION:
  client A has WRITE access
  pager_sync() is called asynchronously
  client A syncs with a m_o_data_return, but keeps a copy of the data
  near simultaneously, client B requests access and libpager requests a flush
  client A answers with a new m_o_data_return containing data different from the first
  libpager sees the first m_o_data_return and hands it out to client B
  RESULT: client B does not have the most recent changes to the data
  [ ] SOLUTION 1: if m_o_data_return indicates kernal_copy=true, we can't hand it out to other clients
         PROBLEM: m_o_data_return doesn't indicate if the kernel has released WRITE access,
                  so this doesn't work if client B is requesting READ access and the lock
                  request is only to revoke WRITE access
  [X] SOLUTION 2: when we request a flush, wait for a lock_completed message
